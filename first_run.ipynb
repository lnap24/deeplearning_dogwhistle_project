{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6043bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarShot Project Starter Notebook\n",
    "# ---------------------------------\n",
    "# Sections: Data Loading, Preprocessing, Embedding, Vector DB Creation\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a213444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Config\n",
    "# -------------------------------\n",
    "DATASET_NAME = \"SALT-NLP/silent_signals\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "VECTOR_DB_PATH = \"./vector_store\"\n",
    "CLASSIFIER_MODEL = \"tomh/toxigen_hatebert\"\n",
    "# unitary/toxic-bert didnt seem to work that well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e07fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Silent Signals dataset...\n",
      "Loaded 16258 labeled entries.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Load Dataset\n",
    "# -------------------------------\n",
    "print(\"Loading Silent Signals dataset...\")\n",
    "dataset = load_dataset(DATASET_NAME, split='train')\n",
    "df = pd.DataFrame(dataset)\n",
    "# Clean Dataset\n",
    "# drop the party, chamber, and speaker columns\n",
    "df = df.drop(columns=['party', 'chamber', 'speaker'])\n",
    "# Filter if necessary (e.g., only Reddit posts, or only dog-whistle-labeled)\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(df)} labeled entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0c4bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72a34e6959245a1b519b170eacc2dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Sentence Embeddings\n",
    "# -------------------------------\n",
    "print(\"Generating embeddings...\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "texts = df['content'].tolist()  # Adjust column name if needed\n",
    "embeddings = model.encode(texts, batch_size=32, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a646d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ChromaDB vector store...\n",
      "Collection deletion failed or doesn't exist yet: Collection [earshot] does not exists\n",
      "Stored 16258 vectors in ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating ChromaDB vector store...\")\n",
    "chroma_client = chromadb.Client(Settings(persist_directory=VECTOR_DB_PATH))\n",
    "# reset the collection if it exists\n",
    "try:\n",
    "    chroma_client.delete_collection(\"earshot\")\n",
    "except Exception as e:\n",
    "    print(\"Collection deletion failed or doesn't exist yet:\", e)\n",
    "collection = chroma_client.create_collection(\"earshot\")\n",
    "\n",
    "# Add embeddings to vector DB (skip numpy by converting to list via torch.tolist())\n",
    "for i, (text, emb) in enumerate(zip(texts, embeddings)):\n",
    "    collection.add(\n",
    "        documents=[text],\n",
    "        embeddings=[emb.cpu().tolist()],\n",
    "        ids=[f\"doc_{i}\"]\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(texts)} vectors in ChromaDB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57b62d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors for: I'm buying a copy of this book and gifting it to every centipede I know in BASED Tuscola County for every Milo hater in this thread. It looks like I'm already up to quite a few copies.\n",
      " - I'm buying a copy of this book and gifting it to every centipede I know in BASED Tuscola County for every Milo hater in this thread. It looks like I'm already up to quite a few copies.\n",
      " - gay centipedes have every reason to be proud today. We have based Milo who is not going to back down in the face of gun violence.\n",
      " - I pre-ordered his book hours after it was announced. I urge all other centipedes to support the cause :-)\n",
      " - Milo, as every homosexual, is a broken person, a product of a broken family and childhood environment. The result of that brokenness is depravity.... I'm not a fan of milo in any sense of the word.\n",
      " - same here ~ *Milo the Fabulous* taught me about **Andrew Breitbart** rather early on during #GamerGate, and I'm so glad he did ❤🎮❤ USA 🏴 🏁 🏳\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Nearest Neighbor Retrieval\n",
    "# -------------------------------\n",
    "def get_neighbors(query_text, k=5):\n",
    "    query_emb = model.encode([query_text], convert_to_tensor=True)[0].cpu().tolist()\n",
    "    results = collection.query(query_embeddings=[query_emb], n_results=k)\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "example_query = texts[12]\n",
    "neighbors = get_neighbors(example_query)\n",
    "print(\"Nearest Neighbors for:\", example_query)\n",
    "for doc in neighbors['documents'][0]:\n",
    "    print(\" -\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a005019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading custom toxicity classifier model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PREDICT on nearest neighbors...\n",
      "Retrieved 5 neighbor posts.\n",
      "Neighbor 1 | Toxicity Score: 0.970\n",
      "Neighbor 1 | Toxic: True\n",
      "Neighbor 2 | Toxicity Score: 0.710\n",
      "Neighbor 2 | Toxic: True\n",
      "Neighbor 3 | Toxicity Score: 0.008\n",
      "Neighbor 3 | Toxic: False\n",
      "Neighbor 4 | Toxicity Score: 0.155\n",
      "Neighbor 4 | Toxic: False\n",
      "Neighbor 5 | Toxicity Score: 0.030\n",
      "Neighbor 5 | Toxic: False\n",
      "PREDICT returned 2 toxic posts with keywords.\n",
      "Post: I'm buying a copy of this book and gifting it to every centipede I know in BASED Tuscola County for every Milo hater in this thread. It looks like I'm already up to quite a few copies.\n",
      "Extracted Keywords: ['BASED Tuscola County', 'BASED Tuscola', 'Tuscola County', 'Milo hater', 'buying a copy']\n",
      "Post: gay centipedes have every reason to be proud today. We have based Milo who is not going to back down in the face of gun violence.\n",
      "Extracted Keywords: ['gay centipedes', 'proud today', 'gay', 'today', 'based Milo']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# PREDICT Pipeline: Filter + Keyword Extraction\n",
    "# -------------------------------\n",
    "\n",
    "# Load classifier manually to bypass numpy issue\n",
    "print(\"Loading custom toxicity classifier model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(CLASSIFIER_MODEL)\n",
    "# Add padding token if missing\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load model and resize its embedding matrix\n",
    "classifier_model = AutoModelForSequenceClassification.from_pretrained(CLASSIFIER_MODEL)\n",
    "classifier_model.resize_token_embeddings(len(tokenizer))\n",
    "classifier_model.eval()\n",
    "\n",
    "# Initialize YAKE keyword extractor\n",
    "kw_extractor = yake.KeywordExtractor(top=5, stopwords=None)\n",
    "\n",
    "def is_toxic(text, threshold=0.5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)[0]\n",
    "    toxic_score = probs[1].item()  # assuming label 1 = toxic\n",
    "    return toxic_score >= threshold\n",
    "\n",
    "def extract_keywords(text):\n",
    "    return [kw for kw, score in kw_extractor.extract_keywords(text)]\n",
    "\n",
    "# Run PREDICT on neighbors of example query\n",
    "print(\"Running PREDICT on nearest neighbors...\")\n",
    "example_query = texts[12]\n",
    "neighbors = get_neighbors(example_query, k=5)\n",
    "predict_results = []\n",
    "\n",
    "print(f\"Retrieved {len(neighbors['documents'][0])} neighbor posts.\")\n",
    "\n",
    "def get_toxic_score(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier_model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)[0]\n",
    "    return probs[1].item()\n",
    "\n",
    "for i, post in enumerate(neighbors['documents'][0]):\n",
    "    score_raw = get_toxic_score(post)\n",
    "    print(f\"Neighbor {i+1} | Toxicity Score: {score_raw:.3f}\")\n",
    "    if score_raw >= 0.3:\n",
    "        print(f\"Neighbor {i+1} | Toxic: True\")\n",
    "        keywords = extract_keywords(post)\n",
    "        predict_results.append({\n",
    "            'post': post,\n",
    "            'keywords': keywords\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Neighbor {i+1} | Toxic: False\")\n",
    "\n",
    "print(f\"PREDICT returned {len(predict_results)} toxic posts with keywords.\")\n",
    "for result in predict_results:\n",
    "    print(\"Post:\", result['post'])\n",
    "    print(\"Extracted Keywords:\", result['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f5f88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running DIRECT on nearest neighbors...\n",
      "\n",
      "Post: I'm buying a copy of this book and gifting it to every centipede I know in BASED Tuscola County for every Milo hater in this thread. It looks like I'm already up to quite a few copies.\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"is_dog_whistle\": true,\n",
      "  \"dog_whistle_terms\": [\"centipede\", \"BASED\", \"Milo\"],\n",
      "  \"explanation\": \"The term 'centipede' is often used in alt-right circles to refer to supporters of Donald Trump, originating from a meme. 'BASED' is slang used in online communities to describe someone who is seen as being true to themselves and not caring about how others perceive them, often used in a context that aligns with far-right ideologies. 'Milo' likely refers to Milo Yiannopoulos, a controversial figure known for his far-right views. The combination of these terms suggests an alignment with alt-right or far-right ideologies, which can be considered a form of covert hate speech or dog whistle.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Post: gay centipedes have every reason to be proud today. We have based Milo who is not going to back down in the face of gun violence.\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"is_dog_whistle\": true,\n",
      "  \"dog_whistle_terms\": [\"gay centipedes\", \"based Milo\"],\n",
      "  \"explanation\": \"The term 'gay centipedes' is a reference to a meme associated with the alt-right and is used to mock or belittle LGBTQ+ individuals. 'Based Milo' refers to Milo Yiannopoulos, a controversial figure known for his far-right views. The combination of these terms suggests an underlying message that aligns with alt-right ideologies, which can be considered a form of covert hate speech or dog whistle.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Post: I pre-ordered his book hours after it was announced. I urge all other centipedes to support the cause :-)\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"is_dog_whistle\": true,\n",
      "  \"dog_whistle_terms\": [\"centipedes\"],\n",
      "  \"explanation\": \"The term 'centipedes' is often used as a dog whistle within certain online communities, particularly those associated with alt-right or far-right ideologies. It originated from a popular video among supporters of Donald Trump during the 2016 U.S. presidential campaign and has since been used to refer to his supporters or those aligned with similar ideologies. The use of this term in the context of urging support for a cause suggests an appeal to this specific group.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Post: Milo, as every homosexual, is a broken person, a product of a broken family and childhood environment. The result of that brokenness is depravity.... I'm not a fan of milo in any sense of the word.\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"is_dog_whistle\": true,\n",
      "  \"dog_whistle_terms\": [\"broken person\", \"broken family\", \"depravity\"],\n",
      "  \"explanation\": \"The post uses terms like 'broken person', 'broken family', and 'depravity' to perpetuate harmful stereotypes about homosexuals, suggesting that they are inherently flawed or morally corrupt due to their sexual orientation. These terms are often used in covert hate speech to demean and dehumanize LGBTQ+ individuals.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Post: same here ~ *Milo the Fabulous* taught me about **Andrew Breitbart** rather early on during #GamerGate, and I'm so glad he did ❤🎮❤ USA 🏴 🏁 🏳\n",
      "LLM Response: ```json\n",
      "{\n",
      "  \"is_dog_whistle\": true,\n",
      "  \"dog_whistle_terms\": [\"Milo the Fabulous\", \"Andrew Breitbart\", \"#GamerGate\"],\n",
      "  \"explanation\": \"The post references 'Milo the Fabulous' likely referring to Milo Yiannopoulos, a controversial figure known for his far-right views. 'Andrew Breitbart' is the founder of Breitbart News, a platform associated with alt-right ideologies. '#GamerGate' was a movement that, while initially about ethics in gaming journalism, became associated with harassment and misogyny. The combination of these references suggests an alignment with far-right ideologies, which can be considered a dog whistle to those familiar with these figures and events.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# DIRECT Pipeline: LLM Prompting for Dog Whistle Detection\n",
    "# -------------------------------\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = openai.OpenAI()\n",
    "\n",
    "def call_llm_direct(post):\n",
    "    prompt = f\"\"\"\n",
    "You are a content moderation assistant. Identify whether the following post contains any covert hate speech or dog whistles.\n",
    "\n",
    "Return your response in the following JSON format:\n",
    "{{\n",
    "  \"is_dog_whistle\": true/false,\n",
    "  \"dog_whistle_terms\": [\"term1\", \"term2\", ...],\n",
    "  \"explanation\": \"brief explanation of detection or why it's not a dog whistle\"\n",
    "}}\n",
    "\n",
    "Post: \"{post}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Run DIRECT on neighbors of example query\n",
    "print(\"\\nRunning DIRECT on nearest neighbors...\")\n",
    "direct_results = []\n",
    "\n",
    "for post in neighbors['documents'][0]:\n",
    "    try:\n",
    "        analysis = call_llm_direct(post)\n",
    "        direct_results.append({\n",
    "            'post': post,\n",
    "            'llm_response': analysis\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(\"Error calling LLM:\", e)\n",
    "\n",
    "# Show results\n",
    "for result in direct_results:\n",
    "    print(\"\\nPost:\", result['post'])\n",
    "    print(\"LLM Response:\", result['llm_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde471f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
